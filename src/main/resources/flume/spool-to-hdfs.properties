agent1.sources = source1
agent1.sinks = sink1
agent1.channels = channel1

agent1.sources.source1.channels = channel1
agent1.sinks.sink1.channel = channel1

agent1.sources.source1.type = spooldir
agent1.sources.source1.spoolDir = /tmp/spooldir

agent1.sources.source1.interceptors = interceptor1
agent1.sources.source1.interceptors.interceptor1.type = timestamp

agent1.sinks.sink1.type = hdfs
# day-sized partitions
# The partition that a Flume event is written to is determined by the timestamp header on the event
agent1.sinks.sink1.hdfs.path = /tmp/flume/year=%Y/month=%m/day=%d
agent1.sinks.sink1.hdfs.filePrefix = events
agent1.sinks.sink1.hdfs.fileSuffix = .log
agent1.sinks.sink1.hdfs.inUsePrefix = _
agent1.sinks.sink1.hdfs.fileType = DataStream

# the HDFS sink has a setting, hdfs.useLocal TimeStamp, that will use a timestamp generated by the Flume agent running the HDFS sink.
agent1.channels.channel1.type = file

# a typical temporary filename would be _events. 1399295780136.log.tmp;
# the number is a timestamp generated by the HDFS sink.
